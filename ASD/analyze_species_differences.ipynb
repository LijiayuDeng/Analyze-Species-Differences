{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e391201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All initial conditions are met.\n",
      "Condition check passed, starting data analysis...\n",
      "Data successfully read, number of columns: 301\n",
      "Selected top 40 modules: ['M00555 Betaine biosynthesis, choline => betaine', 'M00554 UDP-Gal biosynthesis, Gal => UDP-Gal', 'M00144 NADH:quinone oxidoreductase, prokaryotes', 'M00948 Hydroxyproline degradation, trans-4-hydroxy-L-proline => 2-oxoglutarate', 'M00854 Glycogen biosynthesis, glucose-1P => glycogen/starch', 'M00038 Tryptophan metabolism, tryptophan => kynurenine => 2-aminomuconate', 'M00156 Cytochrome c oxidase, cbb3-type', 'M00565 Trehalose biosynthesis, D-glucose 1P => trehalose', 'M00529 Denitrification, nitrate => nitrogen', 'M00122 Cobalamin biosynthesis, cobyrinate a,c-diamide => cobalamin', 'M01000 GDP-Man biosynthesis, Fru-6P => GDP-Man', 'M00632 Galactose degradation, Leloir pathway, galactose => alpha-D-glucose-1P', 'M00793 dTDP-L-rhamnose biosynthesis, glucose-1P => dTDP-L-Rha', 'M00855 Glycogen degradation, glycogen => glucose-6P', 'M00150 Fumarate reductase, prokaryotes', 'M00175 Nitrogen fixation, nitrogen => ammonia', 'M00091 Phosphatidylcholine (PC) biosynthesis, PE => PC', 'M00912 NAD biosynthesis, tryptophan => quinolinate => NAD', 'M00744 Cationic antimicrobial peptide (CAMP) resistance, protease PgtE', 'M00136 GABA biosynthesis, prokaryotes, putrescine => GABA', 'M00924 Cobalamin biosynthesis, anaerobic, uroporphyrinogen III => sirohydrochlorin => cobyrinate a,c-diamide', 'M00649 Multidrug resistance, efflux pump AdeABC', 'M00842 Tetrahydrobiopterin biosynthesis, GTP => BH4', 'M00843 L-threo-Tetrahydrobiopterin biosynthesis, GTP => L-threo-BH4', 'M00718 Multidrug resistance, efflux pump MexAB-OprM', 'M00061 D-Glucuronate degradation, D-glucuronate => pyruvate + D-glyceraldehyde 3P', 'M00999 UDP-GlcA/GalA biosynthesis, UDP-Glc => UDP-GlcA => UDP-GalA', 'M00123 Biotin biosynthesis, pimeloyl-ACP/CoA => biotin', 'M00546 Purine degradation, xanthine => urea', 'M00631 D-Galacturonate degradation (bacteria), D-galacturonate => pyruvate + D-glyceraldehyde 3P', 'M00064 ADP-L-glycero-D-manno-heptose biosynthesis, sedoheptulose-7P => ADP-LDmanHep', 'M00642 Multidrug resistance, efflux pump MexJK-OprM', 'M00168 CAM (Crassulacean acid metabolism), dark', 'M00745 Imipenem resistance, repression of porin OprD', 'M00133 Polyamine biosynthesis, arginine => agmatine => putrescine => spermidine', 'M00530 Dissimilatory nitrate reduction, nitrate => ammonia', 'M00993 Dimethylsulfoniopropionate (DMSP) degradation, cleavage pathway, DMSP => propionyl-CoA', 'M00552 D-galactonate degradation, De Ley-Doudoroff pathway, D-galactonate => glycerate-3P', 'M00531 Assimilatory nitrate reduction, nitrate => ammonia', 'M00615 Nitrate assimilation']\n",
      "Data saved to: C:\\Users\\lichi\\Desktop\\top_40_modules_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Simplified version: Extract differential module metrics for target species from Excel and output the top_n ranked modules.\n",
    "\n",
    "Functionality Description:\n",
    "1. Check initial conditions: Ensure Python version, necessary libraries, Excel file existence, and data integrity.\n",
    "2. Read data from the Excel file and extract differential module metrics for target species.\n",
    "3. Calculate differential metrics (mean and variance) for each module and perform standardization.\n",
    "4. Sort modules based on combined differences and select the top_n ranked modules.\n",
    "5. Save the results to an Excel file, including selected module data and combined difference rankings.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib.util\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def check_initial_conditions(file_path: str,\n",
    "                             species_col: int = 0,\n",
    "                             modules_start_col: int = 4,\n",
    "                             target_species: Optional[List[str]] = None,\n",
    "                             data_skiprows: int = 4,\n",
    "                             header_skiprows: int = 3) -> bool:\n",
    "    \"\"\"\n",
    "    Check necessary prerequisites: Python version, required libraries, Excel file existence, and data integrity.\n",
    "    \"\"\"\n",
    "    # Check Python version\n",
    "    if sys.version_info < (3, 0):\n",
    "        print(f\"Python 3.x or higher is required, current version: {sys.version_info.major}.{sys.version_info.minor}\")\n",
    "        return False\n",
    "\n",
    "    # Check if required libraries are installed\n",
    "    for pkg in ['pandas', 'numpy', 'openpyxl', 'sklearn']:\n",
    "        if importlib.util.find_spec(pkg) is None:\n",
    "            print(f\"Missing required library: {pkg}\")\n",
    "            return False\n",
    "\n",
    "    # Check if Excel file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Excel file does not exist: {file_path}\")\n",
    "        return False\n",
    "\n",
    "    # Check data integrity\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, na_values=[\"#N/A\"], skiprows=data_skiprows, header=None)\n",
    "        if species_col >= len(df.columns) or modules_start_col >= len(df.columns):\n",
    "            print(\"Specified column index exceeds Excel data range.\")\n",
    "            return False\n",
    "        if target_species:\n",
    "            species_data = df.iloc[:, species_col].values\n",
    "            for sp in target_species:\n",
    "                if sp not in species_data:\n",
    "                    print(f\"Target species '{sp}' does not exist in the data.\")\n",
    "                    return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel data: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(\"All initial conditions are met.\")\n",
    "    return True\n",
    "\n",
    "def extract_top_modules(file_path: str,\n",
    "                        species_col: int = 0,\n",
    "                        modules_start_col: int = 4,\n",
    "                        target_species: List[str] = None,\n",
    "                        top_n: int = 40,\n",
    "                        output_file: Optional[str] = None,\n",
    "                        data_skiprows: int = 4,\n",
    "                        header_skiprows: int = 3) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract differential module metrics for target species, return sorted results and selected top_n module data, and write to Excel file.\n",
    "    \"\"\"\n",
    "    if not target_species:\n",
    "        raise ValueError(\"Please provide at least one target species.\")\n",
    "        \n",
    "    # Read module names row (4th row in Excel)\n",
    "    try:\n",
    "        header_df = pd.read_excel(file_path, na_values=[\"#N/A\"], skiprows=header_skiprows, nrows=1, header=None)\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Failed to read module column names: {e}\")\n",
    "    module_names = header_df.iloc[0, modules_start_col:].tolist()\n",
    "    \n",
    "    # Read actual data (starting from the 5th row)\n",
    "    try:\n",
    "        df_data = pd.read_excel(file_path, na_values=[\"#N/A\"], skiprows=data_skiprows, header=None)\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Failed to read Excel data: {e}\")\n",
    "    df_data.columns = list(range(df_data.shape[1]))\n",
    "    \n",
    "    # Rename module columns\n",
    "    rename_mapping = {col: module_names[col - modules_start_col]\n",
    "                      for col in range(modules_start_col, df_data.shape[1])\n",
    "                      if col - modules_start_col < len(module_names)}\n",
    "    df_data.rename(columns=rename_mapping, inplace=True)\n",
    "    \n",
    "    print(\"Data successfully read, number of columns:\", df_data.shape[1])\n",
    "    \n",
    "    # Extract species names and module data\n",
    "    species_names = df_data.iloc[:, species_col]\n",
    "    modules_data = df_data.iloc[:, modules_start_col:]\n",
    "    modules_data = modules_data.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "    \n",
    "    # Record the index position of target species in the DataFrame (only take the first match)\n",
    "    target_indices = {}\n",
    "    for sp in target_species:\n",
    "        indices = species_names[species_names == sp].index\n",
    "        if len(indices) == 0:\n",
    "            raise ValueError(f\"Target species '{sp}' not found.\")\n",
    "        target_indices[sp] = indices[0]\n",
    "    \n",
    "    module_list = []\n",
    "    diff_metrics = {sp: {\"mean\": [], \"var\": []} for sp in target_species}\n",
    "    \n",
    "    # Calculate differential metrics for each module\n",
    "    for module in modules_data.columns:\n",
    "        values = modules_data[module]\n",
    "        for sp in target_species:\n",
    "            idx = target_indices[sp]\n",
    "            target_value = values.iloc[idx]\n",
    "            diffs = np.abs(values.drop(index=idx) - target_value)\n",
    "            diff_metrics[sp][\"mean\"].append(diffs.mean())\n",
    "            diff_metrics[sp][\"var\"].append(diffs.var())\n",
    "        module_list.append(module)\n",
    "    \n",
    "    # Aggregate metrics: store mean and variance metrics for each module across all target species\n",
    "    data_matrix = []\n",
    "    for i in range(len(module_list)):\n",
    "        row = []\n",
    "        for sp in target_species:\n",
    "            row.append(diff_metrics[sp][\"mean\"][i])\n",
    "            row.append(diff_metrics[sp][\"var\"][i])\n",
    "        data_matrix.append(row)\n",
    "    data_matrix = np.array(data_matrix)\n",
    "    \n",
    "    # Standardize and calculate combined differences\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(data_matrix)\n",
    "    combined = scaled.sum(axis=1)\n",
    "    \n",
    "    # Create result DataFrame and sort\n",
    "    result_df = pd.DataFrame({\n",
    "        'Module': module_list,\n",
    "        'Combined Difference': combined\n",
    "    }).sort_values(by='Combined Difference', ascending=False)\n",
    "    \n",
    "    # Select top_n modules\n",
    "    top_modules = result_df.head(top_n)['Module'].tolist()\n",
    "    print(f\"Selected top {top_n} modules:\", top_modules)\n",
    "    \n",
    "    try:\n",
    "        selected = [df_data.columns[species_col]] + top_modules\n",
    "        top_data = df_data[selected]\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Specified column name error: {e}\")\n",
    "    \n",
    "    # Save results to Excel file\n",
    "    if output_file is None:\n",
    "        desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "        output_file = os.path.join(desktop, f'top_{top_n}_modules_data.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        top_data.to_excel(writer, sheet_name='Top Modules Data', index=False)\n",
    "        result_df.to_excel(writer, sheet_name='Combined Differences', index=False)\n",
    "    \n",
    "    print(\"Data saved to:\", output_file)\n",
    "    return result_df, top_data\n",
    "\n",
    "# Main entry point for testing and actual execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Modify the following parameters as needed\n",
    "    file_path = r'C:\\Users\\lichi\\Desktop\\工作簿1.xlsx'\n",
    "    target_species = ['Aestuariirhabdus_salina_LZHN29T', 'Thalassotalea_salina_PLHSN55T']\n",
    "    species_col = 0              # Column where species names are located\n",
    "    modules_start_col = 4        # Starting column for module data (starting from the 5th column in Excel)\n",
    "    top_n = 40                   # Select top 40 modules\n",
    "    data_skiprows = 4            # Data starts from the 5th row\n",
    "    header_skiprows = 3          # Module names are located in the 4th row\n",
    "\n",
    "    if check_initial_conditions(file_path, species_col, modules_start_col,\n",
    "                                target_species, data_skiprows, header_skiprows):\n",
    "        print(\"Condition check passed, starting data analysis...\")\n",
    "        result_df, top_data = extract_top_modules(file_path,\n",
    "                                                   species_col,\n",
    "                                                   modules_start_col,\n",
    "                                                   target_species,\n",
    "                                                   top_n,\n",
    "                                                   data_skiprows=data_skiprows,\n",
    "                                                   header_skiprows=header_skiprows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
